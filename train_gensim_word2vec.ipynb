{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning item embeddings with Gensim's Word2Vec\n",
    "\n",
    "< some kind of discussion > \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "from copy import deepcopy \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "from recsys.data import load_ecomm, train_test_split\n",
    "from recsys.metrics import recall_at_k\n",
    "from recsys.utils import absolute_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick exploration of the data (products in the Online Retail dataset) \n",
    "\n",
    "There's an entire notebook on this in the Session-Based Recommenders repo. Just pull some of the good bits an dput them here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up training\n",
    "\n",
    "What do we need to train good item embeddings? \n",
    "\n",
    "A few ingredients. \n",
    "- Logging \n",
    "- hyperparameter optimization\n",
    "- early stopping \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging with Gensim Callbacks\n",
    "\n",
    "A loss logger is pretty standard but it turns out that Gensim's loss logging for the word2vec model is a little buggy. Many times, this metric provides little value because it is measuring the training loss compared to... blah blah blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossLogger(CallbackAny2Vec):\n",
    "    '''Report training loss at each epoch'''\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.previous_loss = 0\n",
    "        self.training_loss = []\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        # the loss output by Word2Vec is more akin to a cumulative loss and increases each epoch\n",
    "        # to get a value closer to loss per epoch, we subtract\n",
    "        cumulative_loss = model.get_latest_training_loss()\n",
    "        loss = cumulative_loss - self.previous_loss\n",
    "        self.previous_loss = cumulative_loss\n",
    "        self.training_loss.append(loss)\n",
    "        print(f' Loss: {loss}')\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word2vec is used to learn embeddings for individual words or word pieces, but these embeddings are hardly the ultimate goal. Instead, these embeddings are usually created with some other downstream task in mind. If that task is known, a more useful logging metric is one that measures the downstream task. Such metrics could include\n",
    "\n",
    "- example\n",
    "- example\n",
    "- example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecallAtKLogger(CallbackAny2Vec):\n",
    "    '''Report Recall@K at each epoch'''\n",
    "    def __init__(self, validation_set, k, ray_tune=False, save_model=False):\n",
    "        self.epoch = 0\n",
    "        self.recall_scores = []\n",
    "        self.validation = validation_set\n",
    "        self.k = k\n",
    "        self.tune = ray_tune\n",
    "        self.save = save_model\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        if not self.tune:\n",
    "            print(f'Epoch: {self.epoch}', end='\\t')\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        # method 1: deepcopy the model and set the model copy's wv to None\n",
    "        mod = deepcopy(model)\n",
    "        mod.wv.norms = None # will cause it recalculate norms? \n",
    "        \n",
    "        # Every 10 epochs, save the model \n",
    "        if self.epoch%10 == 0 and self.save: \n",
    "            # method 2: save and reload the. model\n",
    "            model.save(absolute_filename(f\"{MODEL_DIR}w2v_{self.epoch}.model\"))\n",
    "            #mod = Word2Vec.load(f\"w2v_{self.epoch}.model\")\n",
    "        \n",
    "        ratk_score = recall_at_k(self.validation, mod.wv, self.k)  \n",
    "\n",
    "        if self.tune: \n",
    "            tune.report(recall_at_k = ratk_score)    \n",
    "        else:\n",
    "            self.recall_scores.append(ratk_score)\n",
    "            print(f' Recall@10: {ratk_score}')\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a wrapper to train our word2vec model. We'll allow it to be trained with or without the Callbacks above (to provide additional flexibility). After training, this function returns the all-important embeddings vectors. \n",
    "\n",
    "Potential Pitfalls: starting and stopping training -- don't do it!! Just train all at once. Explain why. \n",
    "(Start and end learning rate becomes saw-tooth.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_w2v(train_data, params:dict, callbacks=None, model_name=None):\n",
    "    if model_name: \n",
    "        # Load a model for additional training. \n",
    "        model = Word2Vec.load(model_name)\n",
    "    else: \n",
    "        # train model\n",
    "        if callbacks:\n",
    "            model = Word2Vec(callbacks=callbacks, **params)\n",
    "        else:\n",
    "            model = Word2Vec(**params)\n",
    "        model.build_vocab(train_data)\n",
    "\n",
    "    model.train(train_data, total_examples=model.corpus_count, epochs=model.epochs, compute_loss=True)\n",
    "    vectors = model.wv\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_w2v(config):\n",
    "    # load data\n",
    "    if config['dataset'] == 'recsys15':\n",
    "        sessions = load_recsys15()\n",
    "    elif config['dataset'] == 'aotm':\n",
    "        sessions = load_aotm()\n",
    "    elif config['dataset'] == 'ecomm':\n",
    "        sessions = load_ecomm()\n",
    "    else:\n",
    "        print(f\"{config['dataset']}  is not a valid dataset name. Please choose from recsys15, aotm or ecomm\")\n",
    "        return \n",
    "\n",
    "    train, test, valid = train_test_split(sessions, test_size=1000)\n",
    "    ratk_logger = RecallAtKLogger(valid, k=config['k'], ray_tune=True)\n",
    "\n",
    "    # remove keys from config that aren't hyperparameters of word2vec\n",
    "    config.pop('dataset')\n",
    "    config.pop('k')\n",
    "    train_w2v(train, params=config, callbacks=[ratk_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperperamter optimization and early stopping with Ray Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.2/16.0 GiB<br>Using AsyncHyperBand: num_stopped=6\n",
       "Bracket: Iter 40.000: None | Iter 10.000: 0.221<br>Resources requested: 0/12 CPUs, 0/0 GPUs, 0.0/4.54 GiB heap, 0.0/1.56 GiB objects<br>Current best trial: d9252_00000 with recall_at_k=0.228 and parameters={'negative': 1, 'iter': 10, 'min_count': 1, 'workers': 6, 'sg': 1}<br>Result logdir: /Users/mbeck/Projects/gensim_amp/ray_results/tune_w2v_2021-07-13_13-33-41<br>Number of trials: 7/7 (7 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-13 13:34:42,795\tINFO tune.py:450 -- Total run time: 60.91 seconds (60.89 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter search space for Word2Vec algorithm\n",
    "search_space = {\n",
    "    \"dataset\": \"ecomm\",\n",
    "    \"k\": 10,\n",
    "    #\"size\": ### Hyperperamter optimization and early stopping with Ray Tunetune.grid_search(list(np.arange(10,106, 6))),\n",
    "    #\"window\": tune.grid_search(list(np.arange(1,22, 3))),\n",
    "    #\"ns_exponent\": tune.grid_search(list(np.arange(-1, 1.2, .2))),\n",
    "    #\"alpha\": tune.grid_search([0.001, 0.01, 0.1]),\n",
    "    \"negative\": tune.grid_search(list(np.arange(1,22, 3))),\n",
    "    \"iter\": 10,\n",
    "    \"min_count\": 1,\n",
    "    \"workers\": 6,\n",
    "    \"sg\": 1,\n",
    "}\n",
    "\n",
    "# The ASHA Scheduler will stop underperforming trials in a principled fashion\n",
    "asha_scheduler = ASHAScheduler(max_t=100, grace_period=10) \n",
    "\n",
    "# Set the stopping critera -- use the smoke-test arg to test the system \n",
    "stopping_criteria = {\"training_iteration\": 9999}\n",
    "\n",
    "# Perform hyperparamter sweep with Ray Tune\n",
    "analysis = tune.run(\n",
    "    tune_w2v,\n",
    "    #name=args.name,\n",
    "    local_dir=absolute_filename(\"ray_results\"),\n",
    "    metric=\"recall_at_k\",\n",
    "    mode=\"max\",\n",
    "    scheduler=asha_scheduler,\n",
    "    stop=stopping_criteria,\n",
    "    num_samples=1,\n",
    "    verbose=1,\n",
    "    resources_per_trial={\n",
    "        \"cpu\": 1,\n",
    "        \"gpu\": 0\n",
    "    },\n",
    "    config=search_space,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall_at_k</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>done</th>\n",
       "      <th>timesteps_total</th>\n",
       "      <th>episodes_total</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>time_total_s</th>\n",
       "      <th>...</th>\n",
       "      <th>iterations_since_restore</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>config/dataset</th>\n",
       "      <th>config/iter</th>\n",
       "      <th>config/k</th>\n",
       "      <th>config/min_count</th>\n",
       "      <th>config/negative</th>\n",
       "      <th>config/sg</th>\n",
       "      <th>config/workers</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.231</td>\n",
       "      <td>1.542614</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>d6b9e5d4840a4117abb5b5c4582f392d</td>\n",
       "      <td>2021-07-13_13-33-53</td>\n",
       "      <td>1626201233</td>\n",
       "      <td>9.651698</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>d9252_00000</td>\n",
       "      <td>ecomm</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>/Users/mbeck/Projects/gensim_amp/ray_results/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.218</td>\n",
       "      <td>2.382230</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>fb8beb277d6a4cfa9488a838c028ed28</td>\n",
       "      <td>2021-07-13_13-34-09</td>\n",
       "      <td>1626201249</td>\n",
       "      <td>25.747690</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>d9252_00001</td>\n",
       "      <td>ecomm</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>/Users/mbeck/Projects/gensim_amp/ray_results/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.223</td>\n",
       "      <td>3.050999</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>a2865b42445646a1b0b7153a61d6843d</td>\n",
       "      <td>2021-07-13_13-34-20</td>\n",
       "      <td>1626201260</td>\n",
       "      <td>35.698053</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>d9252_00002</td>\n",
       "      <td>ecomm</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>/Users/mbeck/Projects/gensim_amp/ray_results/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.215</td>\n",
       "      <td>3.226812</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>6cf613601c9f41f89f2a3c3d74ed9028</td>\n",
       "      <td>2021-07-13_13-34-27</td>\n",
       "      <td>1626201267</td>\n",
       "      <td>42.866144</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>d9252_00003</td>\n",
       "      <td>ecomm</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>/Users/mbeck/Projects/gensim_amp/ray_results/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.211</td>\n",
       "      <td>3.913614</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>03b03c28984a41cd88fa6d853379b0eb</td>\n",
       "      <td>2021-07-13_13-34-34</td>\n",
       "      <td>1626201274</td>\n",
       "      <td>50.278771</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>d9252_00004</td>\n",
       "      <td>ecomm</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>/Users/mbeck/Projects/gensim_amp/ray_results/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.214</td>\n",
       "      <td>3.129818</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>e8f20226ca704e04916ab87c286a7f74</td>\n",
       "      <td>2021-07-13_13-34-39</td>\n",
       "      <td>1626201279</td>\n",
       "      <td>55.460817</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>d9252_00005</td>\n",
       "      <td>ecomm</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>/Users/mbeck/Projects/gensim_amp/ray_results/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.219</td>\n",
       "      <td>3.349319</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>f90429b07b974a6c95e49a9d0000ff16</td>\n",
       "      <td>2021-07-13_13-34-40</td>\n",
       "      <td>1626201280</td>\n",
       "      <td>56.162628</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>d9252_00006</td>\n",
       "      <td>ecomm</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>/Users/mbeck/Projects/gensim_amp/ray_results/t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   recall_at_k  time_this_iter_s   done  timesteps_total  episodes_total  \\\n",
       "0        0.231          1.542614  False              NaN             NaN   \n",
       "1        0.218          2.382230   True              NaN             NaN   \n",
       "2        0.223          3.050999   True              NaN             NaN   \n",
       "3        0.215          3.226812   True              NaN             NaN   \n",
       "4        0.211          3.913614   True              NaN             NaN   \n",
       "5        0.214          3.129818   True              NaN             NaN   \n",
       "6        0.219          3.349319  False              NaN             NaN   \n",
       "\n",
       "   training_iteration                     experiment_id                 date  \\\n",
       "0                   6  d6b9e5d4840a4117abb5b5c4582f392d  2021-07-13_13-33-53   \n",
       "1                  10  fb8beb277d6a4cfa9488a838c028ed28  2021-07-13_13-34-09   \n",
       "2                  10  a2865b42445646a1b0b7153a61d6843d  2021-07-13_13-34-20   \n",
       "3                  10  6cf613601c9f41f89f2a3c3d74ed9028  2021-07-13_13-34-27   \n",
       "4                  10  03b03c28984a41cd88fa6d853379b0eb  2021-07-13_13-34-34   \n",
       "5                  10  e8f20226ca704e04916ab87c286a7f74  2021-07-13_13-34-39   \n",
       "6                   9  f90429b07b974a6c95e49a9d0000ff16  2021-07-13_13-34-40   \n",
       "\n",
       "    timestamp  time_total_s  ...  iterations_since_restore     trial_id  \\\n",
       "0  1626201233      9.651698  ...                         6  d9252_00000   \n",
       "1  1626201249     25.747690  ...                        10  d9252_00001   \n",
       "2  1626201260     35.698053  ...                        10  d9252_00002   \n",
       "3  1626201267     42.866144  ...                        10  d9252_00003   \n",
       "4  1626201274     50.278771  ...                        10  d9252_00004   \n",
       "5  1626201279     55.460817  ...                        10  d9252_00005   \n",
       "6  1626201280     56.162628  ...                         9  d9252_00006   \n",
       "\n",
       "  config/dataset  config/iter  config/k  config/min_count config/negative  \\\n",
       "0          ecomm           10        10                 1               1   \n",
       "1          ecomm           10        10                 1               4   \n",
       "2          ecomm           10        10                 1               7   \n",
       "3          ecomm           10        10                 1              10   \n",
       "4          ecomm           10        10                 1              13   \n",
       "5          ecomm           10        10                 1              16   \n",
       "6          ecomm           10        10                 1              19   \n",
       "\n",
       "  config/sg  config/workers                                             logdir  \n",
       "0         1               6  /Users/mbeck/Projects/gensim_amp/ray_results/t...  \n",
       "1         1               6  /Users/mbeck/Projects/gensim_amp/ray_results/t...  \n",
       "2         1               6  /Users/mbeck/Projects/gensim_amp/ray_results/t...  \n",
       "3         1               6  /Users/mbeck/Projects/gensim_amp/ray_results/t...  \n",
       "4         1               6  /Users/mbeck/Projects/gensim_amp/ray_results/t...  \n",
       "5         1               6  /Users/mbeck/Projects/gensim_amp/ray_results/t...  \n",
       "6         1               6  /Users/mbeck/Projects/gensim_amp/ray_results/t...  \n",
       "\n",
       "[7 rows x 25 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize ... something? \n",
    "\n",
    "Online retail dataset has *some* metadata but nothing categorical to show \"similarity\". \n",
    "\n",
    "Could visualize the early stopping mechanism. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
